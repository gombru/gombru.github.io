---
layout: page
title: Publications
permalink: /publications/
order: 2
---

### Learning to Learn from Web Data through Deep Semantic Embeddings
**Raul Gomez**, Lluis Gomez, Jaume Gibert, Dismosthenis Karatzas.  
ECCV MULA workshop (Oral), 2018. [[PDF](https://arxiv.org/abs/1808.06368)] [[Slides](https://docs.google.com/presentation/d/10JJCGCN96-f5Rt20db3TYiJsMavFD2ebHNJ91X8ov7I/edit?usp=sharing)]

A performance comparison between different text embeddings for self-supervised learning from images and associated text in an image retrieval setup.
<div class="imgcap">
<img src="/assets/LearningToLearnFromWebData/pipeline_horizontal.png" height="250">
</div>

### Learning from Barcelona Instagram data what Locals and Tourists post about its Neighbourhoods
**Raul Gomez**, Lluis Gomez, Jaume Gibert, Dismosthenis Karatzas.  
ECCV MULA workshop, 2018. [[PDF](https://arxiv.org/abs/1808.06369)]

Learning relations between text, images and Barcelona neighbourhoods to study the differences between locals and tourists in social media publications and their relations with the different neighbourhoods.
<div class="imgcap">
<img src="/assets/BarcelonaNeighbourhoods/pipeline.png" height="250">
</div>

### TextTopicNet - Self-Supervised Learning of Visual Features Through Embedding Images on Semantic Text Spaces
Yash Patel, Lluis Gomez, **Raul Gomez**, Marçal Rusiñol, Dismosthenis Karatzas and CV Jawahar.   
arXiv preprint arXiv:1807.02110, 2018. [[PDF](https://arxiv.org/abs/1807.02110)]  

This work proposes a self-supervised method to learn competitive visual features from wikipedia articles and its associated images.   
<div class="imgcap">
<img src="/assets/publications/TextTopicNet.png" height="250">
</div>

### ICDAR2017 Robust Reading Challenge on COCO-Text
**Raul Gomez**, Baoguang Shi, Lluis Gomez, Lukas Numann, Andreas Veit, Jiri Matas, Serge Belongie and Dismosthenis Karatzas.   
ICDAR, 2017. [[PDF](http://ieeexplore.ieee.org/abstract/document/8270165/)]  

I organized the ICDAR 2017 competition on COCO-Text within the [Robust Reading Competition framework](http://rrc.cvc.uab.es/?ch=5&com=evaluation&task=1&gtv=1) and wrote this competition report. Tasks were text localization, cropped words recognition and end to end. Though the competition is over, the platform is still open for submissions.   
<div class="imgcap">
<img src="/assets/publications/coco-text.png" height="250">
</div>

### FAST: Facilitated and Accurate Scene Text Proposals through FCN Guided Pruning
Dena Bazazian, **Raul Gomez**, Anguelos Nicolaou, Lluis Gomez, Dimosthenis Karatzas and Andrew Bagdanov.   
Pattern Recognition Letters, 2017. [[PDF](http://www.sciencedirect.com/science/article/pii/S0167865517302982)]  

The former DLPR workshop publication lead to this journal publication. We extended our experiments and we improved our algorithm by using the FCN heatmaps to suppress the non-textual regions at the beggining of the text proposals stage, achieving a more efficient pipeline.
<div class="imgcap">
<img src="/assets/publications/fast.jpg" height="300">
</div>

### Improving Text Proposals for Scene Images with Fully Convolutional Networks
Dena Bazazian, **Raul Gomez**, Anguelos Nicolaou, Lluis Gomez, Dimosthenis Karatzas and Andrew Bagdanov.  
ICPR DLPR workshop, 2016. [[PDF](https://arxiv.org/abs/1702.05089)]  

This came out from my MS's thesis. It's about how to use a text detection FCN to improve the text proposals algorithm (developed by [Lluis Gomez i Bigorda](http://lluisgomez.github.io/), one of my advisors). The code for the FCN model training is [here](https://github.com/gombru/TextFCN) and the code for the text proposals pipeline is [here](https://github.com/gombru/TextProposalsInitialSuppression). Watching the FCN detect text in real time is pretty cool.
<div class="imgcap">
<img src="/assets/publications/fcn.gif" height="300">
</div>

